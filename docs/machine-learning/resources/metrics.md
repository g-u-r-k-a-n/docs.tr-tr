---
title: ML.NET ölçümleri
description: ML.NET bir modelin performansını değerlendirmek için kullanılan ölçümleri anlama
ms.date: 12/17/2019
ms.openlocfilehash: 8e823fd8cc344c1b8e0ecd709b527137368cbfa0
ms.sourcegitcommit: 7588136e355e10cbc2582f389c90c127363c02a5
ms.translationtype: MT
ms.contentlocale: tr-TR
ms.lasthandoff: 03/15/2020
ms.locfileid: "79399219"
---
# <a name="evaluate-your-mlnet-model-with-metrics"></a><span data-ttu-id="5a75b-103">ML.NET modelinizi ölçümlerle değerlendirin</span><span class="sxs-lookup"><span data-stu-id="5a75b-103">Evaluate your ML.NET model with metrics</span></span>

<span data-ttu-id="5a75b-104">ML.NET bir modeli değerlendirmek için kullanılan ölçümleri anlayın.</span><span class="sxs-lookup"><span data-stu-id="5a75b-104">Understand the metrics used to evaluate an ML.NET model.</span></span>

<span data-ttu-id="5a75b-105">Değerlendirme ölçümleri, bir modelin gerçekleştirdiği makine öğrenimi görevinin türüne özgür.</span><span class="sxs-lookup"><span data-stu-id="5a75b-105">Evaluation metrics are specific to the type of machine learning task that a model performs.</span></span>

<span data-ttu-id="5a75b-106">Örneğin, sınıflandırma görevi için model, tahmin edilen bir kategorinin gerçek kategoriyle ne kadar iyi eşleştiğini ölçerek değerlendirilir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-106">For example, for the classification task, the model is evaluated by measuring how well a predicted category matches the actual category.</span></span> <span data-ttu-id="5a75b-107">Kümeleme için değerlendirme, kümelenmiş öğelerin birbirine ne kadar yakın olduğuna ve kümeler arasında ne kadar ayrım olduğuna bağlıdır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-107">And for clustering, evaluation is based on how close clustered items are to each other, and how much separation there is between the clusters.</span></span>

## <a name="evaluation-metrics-for-binary-classification"></a><span data-ttu-id="5a75b-108">İkili Sınıflandırma için değerlendirme ölçümleri</span><span class="sxs-lookup"><span data-stu-id="5a75b-108">Evaluation metrics for Binary Classification</span></span>

| <span data-ttu-id="5a75b-109">Ölçümler</span><span class="sxs-lookup"><span data-stu-id="5a75b-109">Metrics</span></span>   |      <span data-ttu-id="5a75b-110">Açıklama</span><span class="sxs-lookup"><span data-stu-id="5a75b-110">Description</span></span>      |  <span data-ttu-id="5a75b-111">Aramak</span><span class="sxs-lookup"><span data-stu-id="5a75b-111">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="5a75b-112">**Doğru -luk**</span><span class="sxs-lookup"><span data-stu-id="5a75b-112">**Accuracy**</span></span> |  <span data-ttu-id="5a75b-113">[Doğruluk,](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) bir test veri kümesi ile doğru tahminlerin oranıdır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-113">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="5a75b-114">Doğru tahmin sayısının toplam giriş örneği sayısına oranıdır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-114">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="5a75b-115">Her sınıfa ait benzer sayıda örnek varsa iyi çalışır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-115">It works well if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="5a75b-116">**1.00'a ne kadar yakınsa o kadar iyi.**</span><span class="sxs-lookup"><span data-stu-id="5a75b-116">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="5a75b-117">Ama tam olarak 1.00 bir sorunu gösterir (genellikle: etiket / hedef sızıntısı, aşırı uydurma, ya da eğitim verileri ile test).</span><span class="sxs-lookup"><span data-stu-id="5a75b-117">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="5a75b-118">Test verileri dengesizse (örneklerin çoğu sınıflardan birine aitolduğunda), veri kümesi küçükse veya puanlar 0,00 veya 1,00'a yaklaşırsa, doğruluk bir sınıflandırıcının etkinliğini gerçekten yakalamaz ve ek ölçümleri denetlemeniz gerekir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-118">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is small, or scores approach 0.00 or 1.00, then accuracy doesn’t really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="5a75b-119">**Auc**</span><span class="sxs-lookup"><span data-stu-id="5a75b-119">**AUC**</span></span> |    <span data-ttu-id="5a75b-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) veya *Alan eğrisi altında* gerçek pozitif oranı vs yanlış pozitif oranı süpürme tarafından oluşturulan eğri altında alan ölçer.</span><span class="sxs-lookup"><span data-stu-id="5a75b-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve* measures the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="5a75b-121">**1.00'a ne kadar yakınsa o kadar iyi.**</span><span class="sxs-lookup"><span data-stu-id="5a75b-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="5a75b-122">Bir modelin kabul edilebilir olması için 0,50'den büyük olması gerekir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-122">It should be greater than 0.50 for a model to be acceptable.</span></span> <span data-ttu-id="5a75b-123">0,50 veya daha az AUC ile bir model değersizdir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-123">A model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="5a75b-124">**AUCPR**</span><span class="sxs-lookup"><span data-stu-id="5a75b-124">**AUCPR**</span></span> | <span data-ttu-id="5a75b-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) veya *Alan Hassas Geri Çağırma eğrisi eğrisi altında*: Sınıflar dengesiz olduğunda tahmin başarısının yararlı ölçüsü (yüksek oranda çarpık veri kümeleri).</span><span class="sxs-lookup"><span data-stu-id="5a75b-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="5a75b-126">**1.00'a ne kadar yakınsa o kadar iyi.**</span><span class="sxs-lookup"><span data-stu-id="5a75b-126">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="5a75b-127">1,00'a yakın yüksek puanlar, sınıflandırıcının doğru sonuçları (yüksek hassasiyet) döndürderken ve tüm olumlu sonuçların çoğunluğunu (yüksek geri çağırma) geri döndürdiğini gösterir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-127">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="5a75b-128">**F1 puanı**</span><span class="sxs-lookup"><span data-stu-id="5a75b-128">**F1-score**</span></span> | <span data-ttu-id="5a75b-129">[F1 skoru](https://en.wikipedia.org/wiki/F1_score) dengeli *F-skoru veya F-ölçümü*olarak da bilinir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-129">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="5a75b-130">Bu hassasiyet ve hatırlama nın harmonik ortalamasıdır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-130">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="5a75b-131">Hassasve Geri Çağırma arasında bir denge aramak istediğinizde F1 Puanı yararlıdır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-131">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="5a75b-132">**1.00'a ne kadar yakınsa o kadar iyi.**</span><span class="sxs-lookup"><span data-stu-id="5a75b-132">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="5a75b-133">F1 skoru en iyi değeri ne kadar 1.00, en kötü puanı ise 0.00'dır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-133">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="5a75b-134">Sınıflandırıcınızın ne kadar hassas olduğunu söyler.</span><span class="sxs-lookup"><span data-stu-id="5a75b-134">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="5a75b-135">İkili sınıflandırma ölçümleri hakkında daha fazla bilgi için aşağıdaki makaleleri okuyun:</span><span class="sxs-lookup"><span data-stu-id="5a75b-135">For further details on binary classification metrics read the following articles:</span></span>

- [<span data-ttu-id="5a75b-136">Doğruluk, Hassasiyet, Geri Çağırma veya F1?</span><span class="sxs-lookup"><span data-stu-id="5a75b-136">Accuracy, Precision, Recall, or F1?</span></span>](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [<span data-ttu-id="5a75b-137">İkili Sınıflandırma Ölçümleri sınıfı</span><span class="sxs-lookup"><span data-stu-id="5a75b-137">Binary Classification Metrics class</span></span>](xref:Microsoft.ML.Data.BinaryClassificationMetrics)
- [<span data-ttu-id="5a75b-138">Hassas Geri Çağırma ve ROC Eğrileri Arasındaki İlişki</span><span class="sxs-lookup"><span data-stu-id="5a75b-138">The Relationship Between Precision-Recall and ROC Curves</span></span>](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="evaluation-metrics-for-multi-class-classification"></a><span data-ttu-id="5a75b-139">Çok Sınıflı Sınıflandırma için değerlendirme ölçümleri</span><span class="sxs-lookup"><span data-stu-id="5a75b-139">Evaluation metrics for Multi-class Classification</span></span>

| <span data-ttu-id="5a75b-140">Ölçümler</span><span class="sxs-lookup"><span data-stu-id="5a75b-140">Metrics</span></span>   |      <span data-ttu-id="5a75b-141">Açıklama</span><span class="sxs-lookup"><span data-stu-id="5a75b-141">Description</span></span>      |  <span data-ttu-id="5a75b-142">Aramak</span><span class="sxs-lookup"><span data-stu-id="5a75b-142">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="5a75b-143">**Mikro Doğruluk**</span><span class="sxs-lookup"><span data-stu-id="5a75b-143">**Micro-Accuracy**</span></span> |  <span data-ttu-id="5a75b-144">[Mikro ortalama Doğruluk,](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) ortalama ölçütünün hesaplanması için tüm sınıfların katkılarını toplar.</span><span class="sxs-lookup"><span data-stu-id="5a75b-144">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="5a75b-145">Doğru tahmin edilen örneklerin bir kısmıdır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-145">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="5a75b-146">Mikro ortalama sınıf üyeliğini hesaba katmaz.</span><span class="sxs-lookup"><span data-stu-id="5a75b-146">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="5a75b-147">Temel olarak, her örnek sınıf çifti doğruluk ölçümüeşit katkıda bulunur.</span><span class="sxs-lookup"><span data-stu-id="5a75b-147">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="5a75b-148">**1.00'a ne kadar yakınsa o kadar iyi.**</span><span class="sxs-lookup"><span data-stu-id="5a75b-148">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="5a75b-149">Çok sınıflı bir sınıflandırma görevinde, sınıf dengesizliği olabileceğinden şüpheleniyorsanız makro doğruluk yerine mikro doğruluk tercih edilir (örn.</span><span class="sxs-lookup"><span data-stu-id="5a75b-149">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="5a75b-150">bir sınıfa diğer sınıflara göre çok daha fazla örnek olabilir).</span><span class="sxs-lookup"><span data-stu-id="5a75b-150">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="5a75b-151">**Makro-Doğruluk**</span><span class="sxs-lookup"><span data-stu-id="5a75b-151">**Macro-Accuracy**</span></span> | <span data-ttu-id="5a75b-152">[Makro-ortalama Doğruluk](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) sınıf düzeyinde ortalama doğruluk.</span><span class="sxs-lookup"><span data-stu-id="5a75b-152">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="5a75b-153">Her sınıf için doğruluk hesaplanır ve makro doğruluğu bu doğrulukların ortalamasıdır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-153">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="5a75b-154">Temel olarak, her sınıf doğruluk ölçümüne eşit olarak katkıda bulunur.</span><span class="sxs-lookup"><span data-stu-id="5a75b-154">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="5a75b-155">Azınlık sınıfları daha büyük sınıflar olarak eşit ağırlık verilir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-155">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="5a75b-156">Makro ortalama metrik, veri kümesinin içerdiği bu sınıftan kaç örnek içerse de, her sınıfa aynı ağırlığı verir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-156">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="5a75b-157">**1.00'a ne kadar yakınsa o kadar iyi.**</span><span class="sxs-lookup"><span data-stu-id="5a75b-157">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="5a75b-158">Her sınıf için ölçümü bağımsız olarak hesaplar ve sonra ortalamayı alır (dolayısıyla tüm sınıfları eşit olarak ele alır)</span><span class="sxs-lookup"><span data-stu-id="5a75b-158">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="5a75b-159">**Günlük kaybı**</span><span class="sxs-lookup"><span data-stu-id="5a75b-159">**Log-loss**</span></span>| <span data-ttu-id="5a75b-160">[Logaritmik kayıp,](http://wiki.fast.ai/index.php/Log_Loss) tahmin girdisinin 0,00 ile 1,00 arasında bir olasılık değeri olduğu bir sınıflandırma modelinin performansını ölçer.</span><span class="sxs-lookup"><span data-stu-id="5a75b-160">[Logarithmic loss](http://wiki.fast.ai/index.php/Log_Loss) measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="5a75b-161">Öngörülen olasılık gerçek etiketten farklılaştınkça günlük kaybı artar.</span><span class="sxs-lookup"><span data-stu-id="5a75b-161">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="5a75b-162">**0.00'a ne kadar yakınsa o kadar iyi.**</span><span class="sxs-lookup"><span data-stu-id="5a75b-162">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="5a75b-163">Mükemmel bir model 0.00 bir günlük kaybı olurdu.</span><span class="sxs-lookup"><span data-stu-id="5a75b-163">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="5a75b-164">Makine öğrenme modellerimizin amacı bu değeri en aza indirmektir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-164">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="5a75b-165">**Günlük Kaybı Azaltma**</span><span class="sxs-lookup"><span data-stu-id="5a75b-165">**Log-Loss Reduction**</span></span> | <span data-ttu-id="5a75b-166">[Logaritmik kayıp azaltma](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) rasgele bir tahmin üzerinde sınıflandırıcı avantajı olarak yorumlanabilir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-166">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="5a75b-167">**1.00'ın mükemmel öngörüler olduğu ve 0.00'ın ortalama tahminleri gösterdiği -inf ve 1.00 aralıkları.**</span><span class="sxs-lookup"><span data-stu-id="5a75b-167">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="5a75b-168">Örneğin, değer 0,20'ye eşitse, "doğru tahmin olasılığı rasgele tahminden %20 daha iyidir" olarak yorumlanabilir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-168">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="5a75b-169">Mikro-doğruluk genellikle daha iyi ML tahminlerin iş ihtiyaçları ile uyumludur.</span><span class="sxs-lookup"><span data-stu-id="5a75b-169">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="5a75b-170">Çok sınıflı bir sınıflandırma görevinin kalitesini seçmek için tek bir metrik seçmek istiyorsanız, genellikle mikro doğruluk olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-170">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="5a75b-171">Örnek, bir destek bileti sınıflandırma görevi için: (destek ekiplerine gelen biletleri haritala)</span><span class="sxs-lookup"><span data-stu-id="5a75b-171">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="5a75b-172">Mikro doğruluk -- gelen bilet ne sıklıkta doğru takıma sınıflandırılır?</span><span class="sxs-lookup"><span data-stu-id="5a75b-172">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="5a75b-173">Makro doğruluk -- ortalama bir takım için, gelen bilet takımiçin ne sıklıkta doğrudur?</span><span class="sxs-lookup"><span data-stu-id="5a75b-173">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="5a75b-174">Makro-doğruluk kilolu küçük takımlar bu örnekte; yılda sadece 10 bilet alan küçük bir takım, yılda 10k biletli büyük bir takım kadar önemlidir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-174">Macro-accuracy overweights small teams in this example; a small team that gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="5a75b-175">Bu durumda mikro-doğruluk daha iyi iş ihtiyacı ile ilişkilidir, "ne kadar zaman / para şirket benim bilet yönlendirme süreci otomatikleştirerek kaydedebilirsiniz".</span><span class="sxs-lookup"><span data-stu-id="5a75b-175">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="5a75b-176">Çok sınıflı sınıflandırma ölçümleri hakkında daha fazla bilgi için aşağıdaki makaleleri okuyun:</span><span class="sxs-lookup"><span data-stu-id="5a75b-176">For further details on multi-class classification metrics read the following articles:</span></span>

- [<span data-ttu-id="5a75b-177">Hassas, Geri Çağırma ve F-Skorunun Mikro ve Makro ortalaması</span><span class="sxs-lookup"><span data-stu-id="5a75b-177">Micro- and Macro-average of Precision, Recall, and F-Score</span></span>](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [<span data-ttu-id="5a75b-178">Dengesiz Dataset ile Çok Sınıflı Sınıflandırma</span><span class="sxs-lookup"><span data-stu-id="5a75b-178">Multiclass Classification with Imbalanced Dataset</span></span>](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="evaluation-metrics-for-regression-and-recommendation"></a><span data-ttu-id="5a75b-179">Regresyon ve Öneri için değerlendirme ölçümleri</span><span class="sxs-lookup"><span data-stu-id="5a75b-179">Evaluation metrics for Regression and Recommendation</span></span>

<span data-ttu-id="5a75b-180">Hem gerileme hem de öneri görevleri bir sayıyı tahmin eder.</span><span class="sxs-lookup"><span data-stu-id="5a75b-180">Both the regression and recommendation tasks predict a number.</span></span> <span data-ttu-id="5a75b-181">Regresyon durumunda, sayı giriş özelliklerinden etkilenen herhangi bir çıkış özelliği olabilir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-181">In the case of regression, the number can be any output property that is influenced by the input properties.</span></span> <span data-ttu-id="5a75b-182">Tavsiye için, sayı genellikle bir derecelendirme değeri (örneğin 1 ile 5 arasında) veya evet/hayır önerisidir (sırasıyla 1 ve 0 ile temsil edilir).</span><span class="sxs-lookup"><span data-stu-id="5a75b-182">For recommendation, the number is usually a rating value (between 1 and 5 for example), or a yes/no recommendation (represented by 1 and 0 respectively).</span></span>

| <span data-ttu-id="5a75b-183">Ölçüm</span><span class="sxs-lookup"><span data-stu-id="5a75b-183">Metric</span></span>   |      <span data-ttu-id="5a75b-184">Açıklama</span><span class="sxs-lookup"><span data-stu-id="5a75b-184">Description</span></span>      |  <span data-ttu-id="5a75b-185">Aramak</span><span class="sxs-lookup"><span data-stu-id="5a75b-185">Look for</span></span> |
|----------|-----------------------|-----------|
| <span data-ttu-id="5a75b-186">**R-Kare**</span><span class="sxs-lookup"><span data-stu-id="5a75b-186">**R-Squared**</span></span> |  <span data-ttu-id="5a75b-187">[R-kare (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination)veya *belirleme katsayısı* -inf ve 1.00 arasındaki bir değer olarak modelin tahmin gücünü temsil eder.</span><span class="sxs-lookup"><span data-stu-id="5a75b-187">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="5a75b-188">1.00 mükemmel bir uyum olduğu anlamına gelir ve skorları negatif olabilir, böylece uyum keyfi olarak kötü olabilir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-188">1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</span></span> <span data-ttu-id="5a75b-189">0,00 puan, modelin etiket için beklenen değeri tahmin ettiğini anlamına gelir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-189">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="5a75b-190">R2, gerçek test veri değerlerinin öngörülen değerlere ne kadar yakın olduğunu ölçer.</span><span class="sxs-lookup"><span data-stu-id="5a75b-190">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="5a75b-191">**1.00'a ne kadar yakınsa, o kadar kaliteli.**</span><span class="sxs-lookup"><span data-stu-id="5a75b-191">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="5a75b-192">Ancak, bazen düşük R-kare değerleri (0,50 gibi) tamamen normal veya senaryo nuz için yeterince iyi olabilir ve yüksek R kare değerleri her zaman iyi değildir ve şüpheli olabilir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-192">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="5a75b-193">**Mutlak kayıp**</span><span class="sxs-lookup"><span data-stu-id="5a75b-193">**Absolute-loss**</span></span> |  <span data-ttu-id="5a75b-194">[Mutlak kayıp](https://en.wikipedia.org/wiki/Mean_absolute_error) veya *Ortalama mutlak hata (MAE),* tahminlerin gerçek sonuçlara ne kadar yakın olduğunu ölçer.</span><span class="sxs-lookup"><span data-stu-id="5a75b-194">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="5a75b-195">Model hatasının, öngörülen etiket değeri ile doğru etiket değeri arasındaki mutlak uzaklık olduğu tüm model hatalarının ortalamasıdır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-195">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="5a75b-196">Bu tahmin hatası, test veri kümesinin her kaydı için hesaplanır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-196">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="5a75b-197">Son olarak, kaydedilen tüm mutlak hatalar için ortalama değer hesaplanır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-197">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="5a75b-198">**0.00'a ne kadar yakınsa, o kadar kaliteli.**</span><span class="sxs-lookup"><span data-stu-id="5a75b-198">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="5a75b-199">Ortalama mutlak hata, ölçülen verilerle aynı ölçeği kullanır (belirli aralıkta normalleştirilmez).</span><span class="sxs-lookup"><span data-stu-id="5a75b-199">The mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="5a75b-200">Mutlak kayıp, Kare-kayıp ve RMS kaybı yalnızca aynı veri kümesinin modelleri veya benzer etiket değeri dağılımına sahip veri kümesi için modeller arasında karşılaştırma yapmak için kullanılabilir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-200">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a similar label value distribution.</span></span> |
| <span data-ttu-id="5a75b-201">**Kare-kayıp**</span><span class="sxs-lookup"><span data-stu-id="5a75b-201">**Squared-loss**</span></span> |  <span data-ttu-id="5a75b-202">[Kare-kayıp](https://en.wikipedia.org/wiki/Mean_squared_error) veya *Ortalama Karehata (MSE)* olarak da adlandırılan *Ortalama Kare sapma (MSD)*, bir regresyon çizgisinin bir dizi test veri değerikümesine ne kadar yakın olduğunu, noktalardan gerileme çizgisine (bu mesafeler E hatalarıdır) ve bunları squaring olarak gösterir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-202">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="5a75b-203">Squaring daha büyük farklılıklara daha fazla ağırlık verir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-203">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="5a75b-204">Her zaman negatif değildir ve **0.00'a yakın değerler daha iyidir.**</span><span class="sxs-lookup"><span data-stu-id="5a75b-204">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="5a75b-205">Verilerinize bağlı olarak, ortalama kare hata için çok küçük bir değer elde etmek imkansız olabilir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-205">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="5a75b-206">**RMS kaybı**</span><span class="sxs-lookup"><span data-stu-id="5a75b-206">**RMS-loss**</span></span> |  <span data-ttu-id="5a75b-207">[RMS kaybı](https://en.wikipedia.org/wiki/Root-mean-square_deviation) veya *Kök Ortalama Karehatası (RMSE)* *(Kök Ortalama Kare Sapması olarak*da adlandırılır), bir model tarafından öngörülen değerler ile modellenen ortamdan gözlenen değerler arasındaki farkı ölçer.</span><span class="sxs-lookup"><span data-stu-id="5a75b-207">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values observed from the environment that is being modeled.</span></span> <span data-ttu-id="5a75b-208">RMS-loss Kare-kayıp kare kökü ve etiket olarak aynı birimler, mutlak kaybı olsa da daha büyük farklılıklara daha fazla ağırlık veren benzer vardır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-208">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the absolute-loss though giving more weight to larger differences.</span></span> <span data-ttu-id="5a75b-209">Kök ortalama kare hatası genellikle deneysel sonuçları doğrulamak için klimatoloji, tahmin ve regresyon analizinde kullanılır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-209">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="5a75b-210">Her zaman negatif değildir ve **0.00'a yakın değerler daha iyidir.**</span><span class="sxs-lookup"><span data-stu-id="5a75b-210">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="5a75b-211">RMSD, ölçek bağımlı olduğu için veri kümeleri arasında değil, belirli bir veri kümesi için farklı modellerin tahmin hatalarını karşılaştırmak için bir doğruluk ölçüsüdür.</span><span class="sxs-lookup"><span data-stu-id="5a75b-211">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="5a75b-212">Regresyon ölçümleri hakkında daha fazla bilgi için aşağıdaki makaleleri okuyun:</span><span class="sxs-lookup"><span data-stu-id="5a75b-212">For further details on regression metrics, read the following articles:</span></span>

- [<span data-ttu-id="5a75b-213">Regresyon Analizi: R-karesini nasıl yorumluyorum ve Fit İyiliğini Nasıl Değerlendiririm?</span><span class="sxs-lookup"><span data-stu-id="5a75b-213">Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?</span></span>](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [<span data-ttu-id="5a75b-214">Regresyon Analizinde R-kare nasıl yorumlanır?</span><span class="sxs-lookup"><span data-stu-id="5a75b-214">How To Interpret R-squared in Regression Analysis</span></span>](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [<span data-ttu-id="5a75b-215">R-Kare tanımı</span><span class="sxs-lookup"><span data-stu-id="5a75b-215">R-Squared Definition</span></span>](https://www.investopedia.com/terms/r/r-squared.asp)
- [<span data-ttu-id="5a75b-216">Ortalama Karehata Tanımı</span><span class="sxs-lookup"><span data-stu-id="5a75b-216">Mean Squared Error Definition</span></span>](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [<span data-ttu-id="5a75b-217">Ortalama Kare hata ve Kök Ortalama Kare hata nedir?</span><span class="sxs-lookup"><span data-stu-id="5a75b-217">What are Mean Squared Error and Root Mean Squared Error?</span></span>](https://www.vernier.com/til/1014/)

## <a name="evaluation-metrics-for-clustering"></a><span data-ttu-id="5a75b-218">Kümeleme için değerlendirme ölçümleri</span><span class="sxs-lookup"><span data-stu-id="5a75b-218">Evaluation metrics for Clustering</span></span>

| <span data-ttu-id="5a75b-219">Ölçüm</span><span class="sxs-lookup"><span data-stu-id="5a75b-219">Metric</span></span>   |      <span data-ttu-id="5a75b-220">Açıklama</span><span class="sxs-lookup"><span data-stu-id="5a75b-220">Description</span></span>      |  <span data-ttu-id="5a75b-221">Aramak</span><span class="sxs-lookup"><span data-stu-id="5a75b-221">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="5a75b-222">**Ortalama Mesafe**</span><span class="sxs-lookup"><span data-stu-id="5a75b-222">**Average Distance**</span></span>|<span data-ttu-id="5a75b-223">Veri noktaları ile atanan kümenin merkezi arasındaki uzaklık ortalaması.</span><span class="sxs-lookup"><span data-stu-id="5a75b-223">Average of the distance between data points and the center of their assigned cluster.</span></span> <span data-ttu-id="5a75b-224">Ortalama uzaklık, veri noktalarının küme santrikoitlerine olan yakınlığının bir ölçüsüdür.</span><span class="sxs-lookup"><span data-stu-id="5a75b-224">The average distance is a measure of proximity of the data points to cluster centroids.</span></span> <span data-ttu-id="5a75b-225">Kümenin ne kadar 'sıkı' olduğunun bir ölçüsüdür.</span><span class="sxs-lookup"><span data-stu-id="5a75b-225">It's a measure of how 'tight' the cluster is.</span></span>|<span data-ttu-id="5a75b-226">**0'a** yakın değerler daha iyidir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-226">Values closer to **0** are better.</span></span> <span data-ttu-id="5a75b-227">Ortalama uzaklık sıfıra ne kadar yakınsa, veriler o kadar kümelenir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-227">The closer to zero the average distance is, the more clustered the data is.</span></span> <span data-ttu-id="5a75b-228">Ancak, küme sayısı artırılırsa bu ölçümün azalacağını ve aşırı durumda (her bir veri noktasının kendi kümesi olduğu durumlarda) sıfıra eşit olacağını unutmayın.</span><span class="sxs-lookup"><span data-stu-id="5a75b-228">Note though, that this metric will decrease if the number of clusters is increased, and in the extreme case (where each distinct data point is its own cluster) it will be equal to zero.</span></span>
|<span data-ttu-id="5a75b-229">**Davies Bouldin Endeksi**</span><span class="sxs-lookup"><span data-stu-id="5a75b-229">**Davies Bouldin Index**</span></span>|<span data-ttu-id="5a75b-230">Küme içindeki uzaklıkların küme arasındaki uzaklıklara ortalama oranı.</span><span class="sxs-lookup"><span data-stu-id="5a75b-230">The average ratio of within-cluster distances to between-cluster distances.</span></span> <span data-ttu-id="5a75b-231">Küme ne kadar sıkı ve kümeler ne kadar uzaksa, bu değer o kadar düşüktür.</span><span class="sxs-lookup"><span data-stu-id="5a75b-231">The tighter the cluster, and the further apart the clusters are, the lower this value is.</span></span>|<span data-ttu-id="5a75b-232">**0'a** yakın değerler daha iyidir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-232">Values closer to **0** are better.</span></span> <span data-ttu-id="5a75b-233">Birbirinden daha uzak ve daha az dağılmış kümeler daha iyi bir skor elde eder.</span><span class="sxs-lookup"><span data-stu-id="5a75b-233">Clusters that are farther apart and less dispersed will result in a better score.</span></span>|
|<span data-ttu-id="5a75b-234">**Normalleştirilmiş Karşılıklı Bilgiler**</span><span class="sxs-lookup"><span data-stu-id="5a75b-234">**Normalized Mutual Information**</span></span>|<span data-ttu-id="5a75b-235">Kümeleme modelini eğitmek için kullanılan eğitim verileri de zemin gerçeği etiketleri (yani denetimli kümeleme) ile birlikte geldiğinde kullanılabilir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-235">Can be used when the training data used to train the clustering model also comes with ground truth labels (that is, supervised clustering).</span></span> <span data-ttu-id="5a75b-236">Normalleştirilmiş Karşılıklı Bilgiler ölçümü, benzer veri noktalarının aynı kümeye atanıp atanmadığını ve birbirinden farklı veri noktalarının farklı kümelere atanıp atanmadığını ölçer.</span><span class="sxs-lookup"><span data-stu-id="5a75b-236">The Normalized Mutual Information metric measures whether similar data points get assigned to the same cluster and disparate data points get assigned to different clusters.</span></span> <span data-ttu-id="5a75b-237">Normalleştirilmiş karşılıklı bilgi 0 ile 1 arasında bir değerdir</span><span class="sxs-lookup"><span data-stu-id="5a75b-237">Normalized mutual information is a value between 0 and 1</span></span>|<span data-ttu-id="5a75b-238">**1'e** yakın değerler daha iyidir</span><span class="sxs-lookup"><span data-stu-id="5a75b-238">Values closer to **1** are better</span></span>|

## <a name="evaluation-metrics-for-ranking"></a><span data-ttu-id="5a75b-239">Sıralama için değerlendirme ölçümleri</span><span class="sxs-lookup"><span data-stu-id="5a75b-239">Evaluation metrics for Ranking</span></span>

| <span data-ttu-id="5a75b-240">Ölçüm</span><span class="sxs-lookup"><span data-stu-id="5a75b-240">Metric</span></span>   |      <span data-ttu-id="5a75b-241">Açıklama</span><span class="sxs-lookup"><span data-stu-id="5a75b-241">Description</span></span>      |  <span data-ttu-id="5a75b-242">Aramak</span><span class="sxs-lookup"><span data-stu-id="5a75b-242">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="5a75b-243">**İndirimli Kümülatif Kazançlar**</span><span class="sxs-lookup"><span data-stu-id="5a75b-243">**Discounted Cumulative Gains**</span></span>|<span data-ttu-id="5a75b-244">İndirimli kümülatif kazanç (DCG) sıralama kalitesinin bir ölçüsüdür.</span><span class="sxs-lookup"><span data-stu-id="5a75b-244">Discounted cumulative gain (DCG) is a measure of ranking quality.</span></span> <span data-ttu-id="5a75b-245">İki varsayımdan türetilmiştir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-245">It is derived from two assumptions.</span></span> <span data-ttu-id="5a75b-246">Bir: Son derece alakalı öğeler sıralama sırasına göre daha yüksek görünürken daha yararlıdır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-246">One: Highly relevant items are more useful when appearing higher in ranking order.</span></span> <span data-ttu-id="5a75b-247">İki: Kullanışlılık, alaka düzeyini, alaka düzeyi ne kadar yüksekse, bir öğeyi o kadar kullanışlı izler.</span><span class="sxs-lookup"><span data-stu-id="5a75b-247">Two: Usefulness tracks relevance that is, the higher the relevance, the more useful an item.</span></span> <span data-ttu-id="5a75b-248">İndirimli kümülatif kazanç, sıralama sırasında belirli bir pozisyon için hesaplanır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-248">Discounted cumulative gain is calculated for a particular position in the ranking order.</span></span> <span data-ttu-id="5a75b-249">İlgi pozisyonuna kadar sıralama dizininin logaritma tarafından bölünmüş alaka derecelendirmesini özetler.</span><span class="sxs-lookup"><span data-stu-id="5a75b-249">It sums the relevance grading divided by the logarithm of the ranking index up to the position of interest.</span></span> <span data-ttu-id="5a75b-250">$\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}}$ Alaka düzeyi derecelendirmeleri, zemin gerçeği etiketleri olarak sıralama eğitim algoritmasına sağlanır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-250">It is calculated using $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ Relevance gradings are provided to a ranking training algorithm as ground truth labels.</span></span> <span data-ttu-id="5a75b-251">Sıralama tablosundaki her pozisyon için bir DCG değeri sağlanır, bu nedenle İndirimli Kümülatif **Kazançlar**adı verilir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-251">One DCG value is provided for each position in the ranking table, hence the name Discounted Cumulative **Gains**.</span></span> |<span data-ttu-id="5a75b-252">**Daha yüksek değerler daha iyidir**</span><span class="sxs-lookup"><span data-stu-id="5a75b-252">**Higher values are better**</span></span>|
|<span data-ttu-id="5a75b-253">**Normalleştirilmiş İndirimli Kümülatif Kazançlar**</span><span class="sxs-lookup"><span data-stu-id="5a75b-253">**Normalized Discounted Cumulative Gains**</span></span>|<span data-ttu-id="5a75b-254">DCG'nin normalleştirilmesi, ölçümün farklı uzunluklarda sıralama listeleri yle karşılaştırılmasına olanak tanır</span><span class="sxs-lookup"><span data-stu-id="5a75b-254">Normalizing DCG allows the metric to be compared for ranking lists of different lengths</span></span>|<span data-ttu-id="5a75b-255">**1'e yakın değerler daha iyidir**</span><span class="sxs-lookup"><span data-stu-id="5a75b-255">**Values closer to 1 are better**</span></span>|

## <a name="evaluation-metrics-for-anomaly-detection"></a><span data-ttu-id="5a75b-256">Anomali Tespiti için değerlendirme ölçümleri</span><span class="sxs-lookup"><span data-stu-id="5a75b-256">Evaluation metrics for Anomaly Detection</span></span>

| <span data-ttu-id="5a75b-257">Ölçüm</span><span class="sxs-lookup"><span data-stu-id="5a75b-257">Metric</span></span>   |      <span data-ttu-id="5a75b-258">Açıklama</span><span class="sxs-lookup"><span data-stu-id="5a75b-258">Description</span></span>      |  <span data-ttu-id="5a75b-259">Aramak</span><span class="sxs-lookup"><span data-stu-id="5a75b-259">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="5a75b-260">**ROC Eğrisi Altındaki Alan**</span><span class="sxs-lookup"><span data-stu-id="5a75b-260">**Area Under ROC Curve**</span></span>|<span data-ttu-id="5a75b-261">Alıcı işleci eğrisialtındaki alan, modelin anormal ve olağan veri noktalarını ne kadar iyi ayırdığını ölçer.</span><span class="sxs-lookup"><span data-stu-id="5a75b-261">Area under the receiver operator curve measures how well the model separates anomalous and usual data points.</span></span>|<span data-ttu-id="5a75b-262">**1'e yakın değerler daha iyidir.**</span><span class="sxs-lookup"><span data-stu-id="5a75b-262">**Values closer to 1 are better**.</span></span> <span data-ttu-id="5a75b-263">Yalnızca 0,5'ten büyük değerler modelin etkinliğini gösterir.</span><span class="sxs-lookup"><span data-stu-id="5a75b-263">Only values greater than 0.5 demonstrate effectiveness of the model.</span></span> <span data-ttu-id="5a75b-264">0,5 veya altındaki değerler, modelin girişleri anormal ve olağan kategorilere rasgele ayırmaktan daha iyi olmadığını gösterir</span><span class="sxs-lookup"><span data-stu-id="5a75b-264">Values of 0.5 or below indicate that the model is no better than randomly allocating the inputs to anomalous and usual categories</span></span>|
|<span data-ttu-id="5a75b-265">**Yanlış Pozitif Sayımda Algılama Oranı**</span><span class="sxs-lookup"><span data-stu-id="5a75b-265">**Detection Rate At False Positive Count**</span></span>|<span data-ttu-id="5a75b-266">Yanlış pozitif sayımda algılama oranı, doğru tanımlanmış anomali sayısının, her yanlış pozitif tarafından indekslenen bir test kümesindeki toplam anomali sayısına oranıdır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-266">Detection rate at false positive count is the ratio of the number of correctly identified anomalies to the total number of anomalies in a test set, indexed by each false positive.</span></span> <span data-ttu-id="5a75b-267">Diğer bir tarihte, her yanlış pozitif öğe için yanlış pozitif sayımda algılama oranı için bir değer vardır.</span><span class="sxs-lookup"><span data-stu-id="5a75b-267">That is, there is a value for detection rate at false positive count for each false positive item.</span></span>|<span data-ttu-id="5a75b-268">**1'e yakın değerler daha iyidir.**</span><span class="sxs-lookup"><span data-stu-id="5a75b-268">**Values closer to 1 are better**.</span></span> <span data-ttu-id="5a75b-269">Yanlış pozitif ler yoksa, bu değer 1</span><span class="sxs-lookup"><span data-stu-id="5a75b-269">If there are no false positives, then this value is 1</span></span>|
